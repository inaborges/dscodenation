{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LinearRegression","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMT2Ot+1Msqu7u1/gGiDGrq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WOxiv3bydu4g","colab_type":"text"},"source":["# Linear Regression\n","## Unique variable\n","\n","We have a dataset formed by $n$ values of $(x,y)$.\n","\n","*Problem*\n","\n","If we get some $x_{new}$ value could we estimate a correspondent $y_{new}$?\n","\n","*Hypothesis 1*\n","\n","We admit a linear relation between $x$ and $y$, i.e.,\n","\\begin{equation}\n","\\hat{y} = a x + b\n","\\end{equation}\n","where $a$ is the linear coeficient or slope and $b$ is the independent term.\n","\n","As we have any guarantee that our hypothesis holds, it's probable that our estimative $\\hat{y}$ differs from the actual $y$. Therefore we have a potential associated error, which we will call residual $r$:\n","\\begin{equation}\n","r = y - \\hat{y} = y - (a x + b) = \\sum_i^n r_i \\implies r_i = y_i - ax_i -b_i\n","\\end{equation}\n","\n","Our estimative could be:\n","1. above the actual value, i.e., $y < \\hat{y} \\implies y - \\hat{y} = r < 0$\n","2. below the actual value, i.e., $y > \\hat{y} \\implies y - \\hat{y} = r > 0$\n","3. equal the actual value, i.e., $y = \\hat{y} \\implies y = \\hat{y} = r = 0$\n","\n","In order to be able to deal with all these cases, we square this residual:\n","\\begin{equation}\n","r^2 = (y - \\hat{y})^2 = (y - (a x + b))^2\n","\\end{equation}\n","\n","Let's improve the notation, treating each sample as $i$. And calculate the sum $S$ of the squared residuals:\n","\\begin{equation}\n","S(a,b) = \\sum_{i=1}^n r_i^2 = \\sum_{i=1}(y_i - \\hat{y}_i)^2 = \\sum_{i=1}(y_i - a x_i - b)^2\n","\\end{equation}\n","as our $n$ $(x,y)$ variables are known, we have a function of the coeficients $(a,b)$.\n","\n","In order to minimize this sum $S$, we will partially derivate this expression towards each variable $a,b$; apply the chain rule and equalize this to zero.\n","\\begin{align}\n","\\frac{\\partial S}{\\partial a} &\n","= \\frac{\\partial S}{\\partial r}\\frac{\\partial r}{\\partial a} = 0\\\\\n","\\frac{\\partial S}{\\partial b} & \n","= \\frac{\\partial S}{\\partial r}\\frac{\\partial r}{\\partial b} = 0\n","\\end{align}\n","\n","Each term is calculated by means of:\n","\\begin{align}\n","\\frac{\\partial S}{\\partial r} &\n","= \\frac{\\mathrm{d} \\sum_{i=1}^n  r_i^2}{\\mathrm{d} r_i} = 2 \\sum_{i=1}^n r_i\n","= 2\\sum_{i=1}^n (y_i-ax_i-b)\\\\\n","\\frac{\\partial r_i}{\\partial a} &= \\frac{\\partial (y_i-ax_i-b)}{\\partial a} = -x_i\\\\\n","\\frac{\\partial r_i}{\\partial b} &= \\frac{\\partial (y_i-ax_i-b)}{\\partial b} = -1\n","\\end{align}\n","\n","We could replace as:\n","\\begin{align}\n","\\frac{\\partial S}{\\partial r}\\frac{\\partial r}{\\partial a}\n","& = 2\\sum_{i=1}^n(y_i-ax_i-b) (-x_i) = - 2 \\sum_{i=1}^n x_i (y_i-ax_i-b)\n","= 0 \\\\\n","\\frac{\\partial S}{\\partial r}\\frac{\\partial r}{\\partial b}\n","& = 2 \\sum_{i=1}^n (y_i-ax_i-b) (-1) \n","= -2 \\sum_{i=1}^n (y_i-ax_i-b)\n","= 0\n","\\end{align}\n","\n","If we evaluate the second expression:\n","\\begin{align}\n","0 &= \\sum_{i=1}^n (y_i-ax_i-b)\n","= \\sum_{i=1}^n y_i - \\sum_{i=1}^n a x_i - \\sum_{i=1}^n b \n","\\end{align}\n","\n","Dividing by $n$ samples we get mean values:\n","\\begin{align}\n","0 = \\frac{\\sum_{i=1}^n y_i}{n} - \\frac{\\sum_{i=1}^n a x_i}{n} - \\frac{\\sum_{i=1}^n b}{n}\n","= \\bar{y} - a \\bar{x} - b\n","\\implies b = \\bar{y} - a \\bar{x}\n","\\end{align}\n","\n","If we replace $b$ in the first derivative expression:\n","\\begin{align}\n","0 &= \\sum_{i=1}^n x_i (y_i-ax_i-b)\n","= \\sum_{i=1}^n x_i (y_i-ax_i-(\\bar{y} - a \\bar{x})) \\\\\n","& = \\sum_{i=1}^n x_i (y_i - ax_i - \\bar{y} + a \\bar{x})\n","= \\sum_{i=1}^n x_i ( y_i - \\bar{y}) - a \\sum_{i=1}^n x_i ( x_i - \\bar{x})\n","\\end{align}\n","\n","Isolating $a$\n","\\begin{align}\n","a = \\frac{\\sum_{i=1}^n x_i ( y_i - \\bar{y})}{\\sum_{i=1}^n x_i ( x_i - \\bar{x})}\n","\\end{align}\n","\n","In a nutshell, linear regression for one variable consist in admit a linear relation between $x$ and $y$, i.e., $\\hat{y}=a+bx$, where the coeficients are determined by:\n","\\begin{align}\n","a &= \\frac{\\sum_{i=1}^n x_i ( y_i - \\bar{y})}{\\sum_{i=1}^n x_i ( x_i - \\bar{x})}\\\\\n","b &= \\bar{y} - a \\bar{x}\n","\\end{align}\n","with the sample means:\n","\\begin{align}\n","\\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}, \\qquad \\bar{y} &= \\frac{\\sum_{i=1}^n y_i}{n}\n","\\end{align}"]},{"cell_type":"markdown","metadata":{"id":"y5czODcCA9Vv","colab_type":"text"},"source":["## Multivariate\n","\n","Hypothesis:\n","\n","Admit a linear relation:\n","\\begin{equation}\n","y = Xb + r\n","\\end{equation}\n","\n","Define the residual as:\n","\\begin{equation}\n","r = y - Xb\n","\\end{equation}\n","\n","Compute the squared residual as:\n","\\begin{align}\n","S(b) &= (y - X b)^T (y - X b)\\\\\n","&=  ( y^T - (X b)^T ) (y - X b)\\\\\n","&=  ( y^T - b^T X^T ) (y - X b)\\\\\n","&=  y^T y - b^T X^T y -  y^T X b + b^T X^T X b\n","\\end{align}\n","\n","The second and third term are equal, like we can see through:\n","\\begin{equation}\n","b^T X^T y = (X b)^T y = y^T X b = X^T y b\n","\\end{equation}\n","\n","The last term could be rewritten as:\n","\\begin{equation}\n","b^T X^T X b = (X^T X b)^T b = X^T X b b^T\n","\\end{equation}\n","\n","If we calculate the partial derivative and equals the result to zero i.e., (null residual):\n","\\begin{align}\n","\\frac{\\partial S}{\\partial b} \n","& =  - 2 X^T y  \\frac{\\partial b^T}{\\partial b}   \n","+ X^T X \\frac{\\partial b^Tb}{\\partial b}\\\\\n","&= - 2 X^T y + 2 X^T X b = 0\n","\\end{align}\n","\n","Therefore we get the coefficient vector as:\n","\\begin{align}\n","X^T y = X^T X b \\implies b = (X^T X)^{-1} X^T y \n","\\end{align}\n","\n","Notice the consistence as we recover our initial hypothesis for the case with a null residual through:\n","\\begin{align}\n","b = (X^T X)^{-1} X^T y = X^{-1}X^{-T} X^T y = X^{-1} y\n","\\end{align}\n","\n","In a nutshell\n","\\begin{equation}\n","y = Xb + r, \\qquad b = (X^T X)^{-1} X^T y\n","\\end{equation}\n","\n","Observation:\n","Remember to add the independent variable as $ x^0=1 $:\n","\n","\\begin{equation}\n","\\begin{Bmatrix}\n","y_1 \\\\\n","y_2 \\\\\n","\\vdots \\\\\n","y_n\n","\\end{Bmatrix}\n","=\n","\\begin{bmatrix}\n","1 & x^{1}_{1} & x^{2}_{1} & \\cdots & x^{m}_{1} \\\\\n","1 & x^{1}_{2} & x^{2}_{2} & \\cdots & x^{m}_{2}  \\\\\n","\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n","1 & x^{1}_{n} & x^{2}_{n} & \\cdots & x^{m}_{n}\n","\\end{bmatrix}\n","\\times\n","\\begin{Bmatrix}\n","b_0 \\\\\n","b_1 \\\\\n","\\vdots \\\\\n","b_m\n","\\end{Bmatrix}\n","+\n","\\begin{Bmatrix}\n","r_1 \\\\\n","r_2 \\\\\n","\\vdots \\\\\n","r_n\n","\\end{Bmatrix}\n","\\end{equation}\n","\n","Hypothesis:\n","1. Fixed regressors (X not stochastic)\n","2. Aleatory error with null mean\n","3. Constant error variance (homoscedasticity)\n","4. No error correlation\n","5. b constant\n","6. Linear model\n","7. Error normal distributed\n"]},{"cell_type":"markdown","metadata":{"id":"qJIiTR_9bf_h","colab_type":"text"},"source":["## $R^2$\n","\n","$R^2$ determination coeficient\n","* quality of estimative\n","* $R^2$ of the $y$ variance explained by the $X$ variance\n","\\begin{equation}\n","R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}, \\qquad\n","SS_{res} = \\sum_{i=1}^n r_i^2, \\qquad\n","SS_{tot} = \\sum_{i=1}^n (y_i - \\bar{y})^2\n","\\end{equation}\n","* $SS_{res}$: squared sum of the residuals $r$\n","* $SS_{tot}$: squared sum of the distance of each variable to $y_i$ to average $\\bar{y}$\n","\n","Estimative and residual\n","\\begin{equation}\n","\\hat{y} = Xb, \\qquad\n","r_i = \\hat{y}_i - y_i\n","\\end{equation}\n","\n","\n","Estimator has a normal distribution\n","\\begin{equation}\n","b\\sim \\mathcal{N}\\left(\\beta,\\sigma^2(X^T X)^{-1}\\right)\n","\\end{equation}\n","\n","Sample variance approximation\n","\\begin{equation}\n","s^2 = \\frac{SS_{res}}{n-(m+1)}\n","\\end{equation}\n","* $n$: number of samples\n","* $m$: number of variables\n","* 1: $x_0$\n","\n","t-Student-statistic\n","\\begin{equation}\n","t_i = \\frac{b_i}{s\\sqrt{(X^T X)^{-1}_{ii}}}\n","\\end{equation}\n","\n","Null hypothesis ($H_0$)\n","* $\\beta_i=0$\n","* the coeficients have no influence\n","\n","\n","If $|t_i| > t(1-\\alpha) \\implies H_0$ could be rejected with at least $(1-\\alpha)$ confidence.\n","\n","where $\\alpha$ is the significance level\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3jaxF7cuUhec","colab_type":"text"},"source":["## Homemade implementation"]},{"cell_type":"code","metadata":{"id":"aQMF7xruzfnK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595291259616,"user_tz":180,"elapsed":1180,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}}},"source":["# Multivariate Linear Regression\n","# Author: Vinícius Rios Fuck\n","# Date: 20/07/2020\n","\n","\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import t\n","\n","# Sample input\n","# Source: https://pt.wikipedia.org/wiki/M%C3%A9todo_dos_m%C3%ADnimos_quadrados\n","\n","d = {\"i\": [1,2,3,4,5,6,7,8,9,10],\n","     \"y\": [122,114,86,134,146,107,68,117,71,98],\n","     \"x1\": [139,126,90,144,163,136,61,62,41,120],\n","     \"x2\": [0.115,0.120,0.105,0.090,0.100,0.120,0.105,0.080,0.100,0.115]\n","}\n","df = pd.DataFrame(data=d)\n","\n","# Adjust input data\n","\n","# select the y variable\n","y = df['y'].to_numpy()\n","# select the X variables\n","X = df.iloc[:,2:].to_numpy()\n","# add x_0 column of ones (independent coeficient)\n","X = np.c_[ np.ones(len(X)), X ]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS3Zrp8SPoAZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595291281100,"user_tz":180,"elapsed":803,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}}},"source":["def LR_predict(x, b):\n","  y_hat = x @ b\n","  return y_hat\n","\n","\n","def squared_sum(x):\n","  squared_x_sum = np.square(x).sum()\n","  return squared_x_sum\n","\n","\n","def residual_f(actual, predict):\n","  residual = actual - predict\n","  return residual\n","\n","\n","def R_2_score(squared_residuals_sum, squared_y_y_bar_distance_sum):\n","  R_2 = 1 - squared_residuals_sum / squared_y_y_bar_distance_sum\n","  return R_2\n","\n","\n","def adjusted_R_2_score(R_2, n, dof):\n","  adjusted_R_2 = 1 - (n-1)/dof * (1-R_2)\n","  return adjusted_R_2\n","\n","\n","# Standard Deviation\n","def std_sample(squared_residuals_sum, dof):\n","  sd_sample = (squared_residuals_sum / dof)**0.5\n","  return sd_sample\n","\n","\n","def t_stat(b, sd_sample, XtX_inv):\n","  t_student_coef = b / (sd_sample * np.diag(XtX_inv)**0.5)\n","  return t_student_coef\n","\n","def significance(confidence=0.975):\n","  alpha = 1 - confidence\n","  return alpha\n","\n","\n","def critical_value_calc(dof, confidence=0.975):\n","  critical_value = t.ppf(confidence, dof)\n","  return critical_value\n","\n","\n","def round_3(input):\n","  return round(input, 3)\n","\n","\n","def exp_2(input):\n","  return '{:.2e}'.format(input)\n","\n","\n","def print_hypothesis(b, p_value, t_student_coef, critical_value, alpha):\n","  cv_out = round_3(critical_value)\n","  alpha_out = round_3(alpha)\n","  print(\"H0: null hypothesis: the coefficients bi are not relevant\\n\")\n","\n","  accept_H0_critical_value = np.zeros(len(b))\n","  accept_H0_p_value = np.zeros(len(b))\n","\n","  for i in range(len(b)): # all variables\n","    t_out = round_3(abs(t_student_coef[i]))\n","    # interpret via critical value\n","    accept_H0_critical_value[i] = (abs(t_student_coef[i]) <= critical_value)\n","    if accept_H0_critical_value[i]:\n","      print(f'Accept H0 that b{i} is not relevant.')\n","      print(f't_student = {t_out} <= critical_value = {cv_out}\\n')\n","    else:\n","      print(f'Reject H0 that b{i} is not relevant.')\n","      print(f't_student = {t_out} > critical_value = {cv_out}\\n')\n","\n","    p_out = exp_2(p_value[i])\n","    # interpret via p-value\n","    accept_H0_p_value[i] = (p_value[i] > alpha)\n","    if accept_H0_p_value[i]:\n","      print(f'Accept H0 that b{i} is not relevant.')\n","      print(f'p_value = {p_out} > alpha = {alpha_out}\\n')\n","    else:\n","      print(f'Reject H0 that b{i} is not relevant.')\n","      print(f'p_value = {p_out} <= alpha = {alpha_out}\\n')\n","\n","  return accept_H0_critical_value, accept_H0_p_value\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-3ysPQVYumY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595291286657,"user_tz":180,"elapsed":909,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}}},"source":["# R^2 (quality of estimative)\n","def R2_SqResidSum(X, y, b):\n","  # y mean\n","  y_bar = y.mean()\n","  # predicted y\n","  y_hat = LR_predict(X, b=b)\n","  # residual\n","  residual = residual_f(y, y_hat)\n","  # squared residuals sum\n","  squared_residuals_sum = squared_sum(residual)\n","  # squared_y_y_bar_distance_sum\n","  squared_y_y_bar_distance_sum = squared_sum(y - y_bar)\n","  # R_2\n","  R_2 = R_2_score(squared_residuals_sum, squared_y_y_bar_distance_sum)\n","  return R_2, squared_residuals_sum"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNXZiMJYj71z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595291291620,"user_tz":180,"elapsed":798,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}}},"source":["# t-Student stats (statistical relevance)\n","def t_student_stats(XtX_inv, b, squared_residuals_sum, R_2,\n","                    confidence=0.975, n=len(y)):\n","  # sample size\n","  # n = len(y)\n","  # number of variables # already take in account the independent coeficient\n","  # m = X.shape[1]\n","  m = len(b)\n","  # degree of freedom\n","  dof = n - m\n","  # adjusted_R_2\n","  adjusted_R_2 = adjusted_R_2_score(R_2, n, dof)\n","  # Standard Deviation\n","  sd_sample = std_sample(squared_residuals_sum, dof)\n","  # t_student_coef\n","  t_student_coef = t_stat(b, sd_sample, XtX_inv)\n","  alpha = significance(confidence)\n","  critical_value = critical_value_calc(dof, confidence)\n","  # calculate the p-value\n","  # 2: two-tailed distribution\n","  p_value = (1 - t.cdf(abs(t_student_coef), dof)) * 2\n","  (accept_H0_critical_value,\n","   accept_H0_p_value) = print_hypothesis(b, p_value, t_student_coef,\n","                                         critical_value, alpha)\n","\n","  dict_H0 = {\"t_student\": t_student_coef,\n","             'p_value': p_value,\n","             'accept_H0_critical_value': accept_H0_critical_value,\n","             'accept_H0_p_value': accept_H0_p_value\n","                }\n","  df_H0 = pd.DataFrame(data=dict_H0)\n","\n","  \n","  return adjusted_R_2, sd_sample, t_student_coef, critical_value, df_H0"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"27yWlfZu-xT4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1595291295580,"user_tz":180,"elapsed":903,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}},"outputId":"8c7788f4-a66f-427c-b645-493a1eccb461"},"source":["# Minimum Least Squares\n","\n","# XtX_inv\n","XtX_inv = np.linalg.inv(X.T @ X)\n","# coeficient vector  \n","b = XtX_inv @ X.T @ y\n","\n","# R^2 (quality of estimative)\n","R_2, squared_residuals_sum = R2_SqResidSum(X, y, b)\n","\n","# t-Student stats (statistical relevance)\n","(adjusted_R_2, sd_sample, t_student_coef, \n"," critical_value, df_H0) = t_student_stats(XtX_inv, b,squared_residuals_sum, R_2,\n","                            confidence=0.975, n=len(y))\n","df_H0\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["H0: null hypothesis: the coefficients bi are not relevant\n","\n","Reject H0 that b0 is not relevant.\n","t_student = 5.641 > critical_value = 2.365\n","\n","Reject H0 that b0 is not relevant.\n","p_value = 7.82e-04 <= alpha = 0.025\n","\n","Reject H0 that b1 is not relevant.\n","t_student = 7.307 > critical_value = 2.365\n","\n","Reject H0 that b1 is not relevant.\n","p_value = 1.62e-04 <= alpha = 0.025\n","\n","Reject H0 that b2 is not relevant.\n","t_student = 3.874 > critical_value = 2.365\n","\n","Reject H0 that b2 is not relevant.\n","p_value = 6.10e-03 <= alpha = 0.025\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>t_student</th>\n","      <th>p_value</th>\n","      <th>accept_H0_critical_value</th>\n","      <th>accept_H0_p_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.641207</td>\n","      <td>0.000782</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.306917</td>\n","      <td>0.000162</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-3.873954</td>\n","      <td>0.006100</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   t_student   p_value  accept_H0_critical_value  accept_H0_p_value\n","0   5.641207  0.000782                       0.0                0.0\n","1   7.306917  0.000162                       0.0                0.0\n","2  -3.873954  0.006100                       0.0                0.0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"hxEm60ERLgLT","colab_type":"text"},"source":["## Validation with Sklearn"]},{"cell_type":"code","metadata":{"id":"FY-ES9XZKluz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1595291325074,"user_tz":180,"elapsed":764,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}},"outputId":"94a9d562-0fd6-4680-e789-90e4cbe516b5"},"source":["from sklearn.linear_model import LinearRegression\n","\n","reg = LinearRegression().fit(X, y)\n","\n","# coeficients b\n","b_skt = reg.coef_.copy()\n","# reference issue: without .copy()\n","# reg.score changes from 0.88728964083039 to -36.13590607656064\n","# because it changes reg.coef_[0]\n","b_skt[0] = reg.intercept_\n","\n","print('b from sklearn and homemade implementation are equal?', \n","      np.allclose(b, b_skt))\n","\n","# R^2\n","R_2_skt = reg.score(X, y)\n","print('R^2 from sklearn and homemade implementation are equal?', \n","      np.allclose(R_2, R_2_skt))\n","\n","# predict\n","x_new = np.array([[1, 3, 5]])\n","skt_predict = reg.predict(x_new)\n","print('predict from sklearn and homemade implementation are equal?', \n","      np.allclose(LR_predict(x_new, b), skt_predict))\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["b from sklearn and homemade implementation are equal? True\n","R^2 from sklearn and homemade implementation are equal? True\n","predict from sklearn and homemade implementation are equal? True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qT7xR7hrVuYU","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595291259625,"user_tz":180,"elapsed":1077,"user":{"displayName":"Vinícius Rios Fuck","photoUrl":"","userId":"16428058857665545856"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3aUsT0bOxyob","colab_type":"text"},"source":["# Logistic Regression"]}]}